# DRBD-Reactor Gateway 配置示例

参考 linstor-gateway 的实现，为 SDS 项目提供 iSCSI、NFS 和 NVMe-oF 网关的 drbd-reactor 配置示例。

## 目录

- [iSCSI 网关配置](#iscsi-网关配置)
- [NFS 网关配置](#nfs-网关配置)
- [NVMe-oF 网关配置](#nvme-of-网关配置)
- [通用资源代理 (OCF)](#通用资源代理-ocf)

---

## iSCSI 网关配置

### 配置文件路径

```
/etc/drbd-reactor.d/sds-iscsi-<resource-name>.toml
```

### 完整配置示例

```toml
# SDS iSCSI Gateway Configuration
# Generated by SDS Controller
# Resource: r0 (DRBD resource with volumes)
# Service IP: 192.168.1.100/24
# IQN: iqn.2024-01.com.example:storage.r0

[promoter]
  [[promoter.resources.r0]]
    runner = "systemd"
    stop-services-on-exit = true
    on-drbd-demote-failure = "reboot-immediate"
    target-as = "Requires"

    start = [
      # Cluster Private Volume (Volume 0)
      "ocf:heartbeat:Filesystem fs_cluster_private device=/dev/drbd0 directory=/var/lib/sds/r0-cluster-private fstype=ext4 run_fsck=no",

      # Block iSCSI port on all nodes before starting
      "ocf:heartbeat:portblock pblock0 ip=192.168.1.100 portno=3260 action=block protocol=tcp",

      # Bring up service IP
      "ocf:heartbeat:IPaddr2 service_ip0 ip=192.168.1.100 cidr_netmask=24",

      # Start iSCSI Target
      "ocf:heartbeat:iSCSITarget target iqn=iqn.2024-01.com.example:storage.r0 portals=192.168.1.100:3260 incoming_username= incoming_password= allowed_initiators= implementation=lio",

      # Export LUNs (Volume 1, 2, ...)
      "ocf:heartbeat:iSCSILogicalUnit lu1 target_iqn=iqn.2024-01.com.example:storage.r0 lun=1 path=/dev/drbd1 product_id=a1b2c3d4 scsi_sn=a1b2c3d4",
      "ocf:heartbeat:iSCSILogicalUnit lu2 target_iqn=iqn.2024-01.com.example:storage.r0 lun=2 path=/dev/drbd2 product_id=e5f6g7h8 scsi_sn=e5f6g7h8",

      # Unblock iSCSI port (only on active node)
      "ocf:heartbeat:portblock portunblock0 ip=192.168.1.100 portno=3260 action=unblock protocol=tcp tickle_dir=/var/lib/sds/r0-cluster-private",
    ]

  [promoter.metadata]
    linstor-gateway-schema-version = 1
```

### 配置说明

#### 1. Cluster Private Volume (Volume 0)
- **用途**: 存储集群状态、tickle 文件等
- **挂载点**: `/var/lib/sds/<resource-name>-cluster-private`
- **文件系统**: ext4/xfs

#### 2. Portblock (Block)
- **用途**: 在非活跃节点上阻止 iSCSI 端口 (3260)
- **协议**: TCP
- **时机**: 在所有资源启动前执行

#### 3. IPaddr2
- **用途**: 配置虚拟服务 IP
- **参数**:
  - `ip`: 服务 IP 地址
  - `cidr_netmask`: CIDR 掩码 (例如 24)

#### 4. iSCSITarget
- **用途**: 配置 iSCSI Target
- **参数**:
  - `iqn`: iSCSI 限定名称
  - `portals`: IP:端口列表
  - `incoming_username`: CHAP 用户名 (可选)
  - `incoming_password`: CHAP 密码 (可选)
  - `allowed_initiators`: 允许的发起端 IQN 列表 (空字符串表示全部允许)
  - `implementation`: 目标实现 (lio, tgt, iet, scst)

#### 5. iSCSILogicalUnit (LUN)
- **用途**: 导出逻辑单元
- **参数**:
  - `target_iqn`: 目标 IQN
  - `lun`: LUN 编号 (通常对应 DRBD volume number)
  - `path`: DRBD 设备路径
  - `product_id`: SCSI 产品 ID (前 8 字节用于 VMware 识别)
  - `scsi_sn`: SCSI 序列号

#### 6. Portblock (Unblock)
- **用途**: 在活跃节点上解除端口阻止
- **tickle_dir**: 用于检测连接的目录

### 多 Service IP 配置

如果有多个 Service IP (例如多路径配置):

```toml
start = [
  "ocf:heartbeat:Filesystem fs_cluster_private device=/dev/drbd0 directory=/var/lib/sds/r0-cluster-private fstype=ext4 run_fsck=no",

  # Block ports for both IPs
  "ocf:heartbeat:portblock pblock0 ip=192.168.1.100 portno=3260 action=block protocol=tcp",
  "ocf:heartbeat:portblock pblock1 ip=192.168.1.101 portno=3260 action=block protocol=tcp",

  # Bring up both service IPs
  "ocf:heartbeat:IPaddr2 service_ip0 ip=192.168.1.100 cidr_netmask=24",
  "ocf:heartbeat:IPaddr2 service_ip1 ip=192.168.1.101 cidr_netmask=24",

  # Start target with both portals
  "ocf:heartbeat:iSCSITarget target iqn=iqn.2024-01.com.example:storage.r0 portals=192.168.1.100:3260 192.168.1.101:3260 incoming_username= incoming_password= allowed_initiators= implementation=lio",

  # Export LUNs
  "ocf:heartbeat:iSCSILogicalUnit lu1 target_iqn=iqn.2024-01.com.example:storage.r0 lun=1 path=/dev/drbd1 product_id=a1b2c3d4 scsi_sn=a1b2c3d4",

  # Unblock ports for both IPs
  "ocf:heartbeat:portblock portunblock0 ip=192.168.1.100 portno=3260 action=unblock protocol=tcp tickle_dir=/var/lib/sds/r0-cluster-private",
  "ocf:heartbeat:portblock portunblock1 ip=192.168.1.101 portno=3260 action=unblock protocol=tcp tickle_dir=/var/lib/sds/r0-cluster-private",
]
```

---

## NFS 网关配置

### 配置文件路径

```
/etc/drbd-reactor.d/sds-nfs-<resource-name>.toml
```

### 完整配置示例

```toml
# SDS NFS Gateway Configuration
# Generated by SDS Controller
# Resource: nfs-data
# Service IP: 192.168.1.200/24
# Export Path: /srv/gateway-exports/nfs-data

[promoter]
  [[promoter.resources.nfs-data]]
    runner = "systemd"
    stop-services-on-exit = true
    on-drbd-demote-failure = "reboot-immediate"
    target-as = "BindsTo"

    start = [
      # Block NFS port on all nodes
      "ocf:heartbeat:portblock portblock ip=192.168.1.200 portno=2049 action=block protocol=tcp",

      # Cluster Private Volume (Volume 0)
      "ocf:heartbeat:Filesystem fs_cluster_private device=/dev/drbd0 directory=/var/lib/sds/nfs-data-cluster-private fstype=ext4 run_fsck=no",

      # Mount filesystems for actual data volumes
      "ocf:heartbeat:Filesystem fs_1 device=/dev/drbd1 directory=/srv/gateway-exports/nfs-data/data fstype=ext4 run_fsck=no",
      "ocf:heartbeat:Filesystem fs_2 device=/dev/drbd2 directory=/srv/gateway-exports/nfs-data/backup fstype=ext4 run_fsck=no",

      # Bring up service IP
      "ocf:heartbeat:IPaddr2 service_ip ip=192.168.1.200 cidr_netmask=24",

      # Start NFS server
      "ocf:heartbeat:nfsserver nfsserver nfs_ip=192.168.1.200 nfs_shared_infodir=/var/lib/sds/nfs-data-cluster-private/nfs nfs_server_scope=192.168.1.200",

      # Export filesystems
      "ocf:heartbeat:exportfs export_1_0 directory=/srv/gateway-exports/nfs-data/data fsid=12345678-1234-1234-1234-123456789abc clientspec=0.0.0.0/0.0.0.0 options=rw,all_squash,anonuid=0,anongid=0",
      "ocf:heartbeat:exportfs export_2_0 directory=/srv/gateway-exports/nfs-data/backup fsid=87654321-4321-4321-4321-cba987654321 clientspec=0.0.0.0/0.0.0.0 options=rw,all_squash,anonuid=0,anongid=0",

      # Unblock NFS port
      "ocf:heartbeat:portblock portunblock ip=192.168.1.200 portno=2049 action=unblock protocol=tcp tickle_dir=/var/lib/sds/nfs-data-cluster-private",
    ]

  [promoter.metadata]
    linstor-gateway-schema-version = 1
```

### 配置说明

#### 1. Portblock (Block)
- **端口**: NFS 默认端口 2049
- **协议**: TCP

#### 2. Cluster Private Volume
- **用途**: 存储 NFS 状态信息
- **路径**: `/var/lib/sds/<resource-name>-cluster-private`

#### 3. Filesystem (Data Volumes)
- **用途**: 挂载实际的数据卷
- **挂载点**: `/srv/gateway-exports/<resource-name>/<export-path>`

#### 4. IPaddr2
- **用途**: NFS 服务 IP
- **参数**: 与 iSCSI 相同

#### 5. nfsserver
- **用途**: 启动 NFS 服务
- **参数**:
  - `nfs_ip`: 服务 IP 地址
  - `nfs_shared_infodir`: 共享信息目录 (用于状态同步)
  - `nfs_server_scope`: NFS 服务器范围 (通常是服务 IP)

#### 6. exportfs
- **用途**: 导出 NFS 文件系统
- **参数**:
  - `directory`: 导出路径
  - `fsid`: 文件系统 ID (UUID 格式，每个导出唯一)
  - `clientspec`: 客户端规格 (CIDR 或 IP/掩码)
  - `options`: NFS 选项

#### 7. Portblock (Unblock)
- **用途**: 在活跃节点上解除端口阻止

### 限制客户端访问

```toml
# 只允许特定网络访问
"ocf:heartbeat:exportfs export_1_0 directory=/srv/gateway-exports/nfs-data/data fsid=12345678-1234-1234-1234-123456789abc clientspec=192.168.1.0/24 options=rw,sync,no_root_squash",
```

### 多导出路径配置

```toml
start = [
  # ... (前面的配置不变)

  # 导出多个路径
  "ocf:heartbeat:exportfs export_1_0 directory=/srv/gateway-exports/nfs-data/data fsid=aaaabbbb-cccc-dddd-eeee-ffff00001111 clientspec=192.168.1.0/24 options=rw,no_root_squash",
  "ocf:heartbeat:exportfs export_1_1 directory=/srv/gateway-exports/nfs-data/data fsid=aaaabbbb-cccc-dddd-eeee-ffff00001111 clientspec=10.0.0.0/8 options=rw,root_squash",

  "ocf:heartbeat:exportfs export_2_0 directory=/srv/gateway-exports/nfs-data/backup fsid=bbbbcccc-dddd-eeee-ffff-111122223333 clientspec=0.0.0.0/0.0.0.0 options=ro",

  # ... (后面的配置不变)
]
```

---

## NVMe-oF 网关配置

### 配置文件路径

```
/etc/drbd-reactor.d/sds-nvmeof-<subsystem-name>.toml
```

### 完整配置示例

```toml
# SDS NVMe-oF Gateway Configuration
# Generated by SDS Controller
# Subsystem: nqn.2024-01.com.example:subsystem.nvme
# Service IP: 192.168.1.150/24

[promoter]
  [[promoter.resources.nqn.2024-01.com.example:subsystem.nvme]]
    runner = "systemd"
    stop-services-on-exit = true
    on-drbd-demote-failure = "reboot-immediate"
    target-as = "Requires"

    start = [
      # Block NVMe-oF port on all nodes
      "ocf:heartbeat:portblock portblock ip=192.168.1.150 portno=4420 action=block protocol=tcp",

      # Cluster Private Volume (Volume 0)
      "ocf:heartbeat:Filesystem fs_cluster_private device=/dev/drbd0 directory=/var/lib/sds/nvme-cluster-private fstype=ext4 run_fsck=no",

      # Bring up service IP
      "ocf:heartbeat:IPaddr2 service_ip ip=192.168.1.150 cidr_netmask=24",

      # Create NVMe subsystem
      "ocf:heartbeat:nvmet-subsystem subsys nqn=nqn.2024-01.com.example:subsystem.nvme serial=a1b2c3d4e5f6g7h8",

      # Create namespaces (volumes)
      "ocf:heartbeat:nvmet-namespace ns_1 nqn=nqn.2024-01.com.example:subsystem.nvme namespace_id=1 backing_path=/dev/drbd1 uuid=11111111-2222-3333-4444-555555555555 nguid=11111111-2222-3333-4444-555555555555",
      "ocf:heartbeat:nvmet-namespace ns_2 nqn=nqn.2024-01.com.example:subsystem.nvme namespace_id=2 backing_path=/dev/drbd2 uuid=66666666-7777-8888-9999-aaaaaaaaaaaa nguid=66666666-7777-8888-9999-aaaaaaaaaaaa",

      # Create NVMe port
      "ocf:heartbeat:nvmet-port port nqns=nqn.2024-01.com.example:subsystem.nvme addr=192.168.1.150 type=tcp",

      # Unblock NVMe-oF port
      "ocf:heartbeat:portblock portunblock ip=192.168.1.150 portno=4420 action=unblock protocol=tcp tickle_dir=/var/lib/sds/nvme-cluster-private",
    ]

  [promoter.metadata]
    linstor-gateway-schema-version = 1
```

### 配置说明

#### 1. Portblock (Block)
- **端口**: NVMe-oF 默认端口 4420
- **协议**: TCP

#### 2. Cluster Private Volume
- **用途**: 存储 NVMe 状态
- **路径**: `/var/lib/sds/nvme-cluster-private`

#### 3. IPaddr2
- **用途**: NVMe-oF 服务 IP

#### 4. nvmet-subsystem
- **用途**: 创建 NVMe 子系统
- **参数**:
  - `nqn`: NVMe 限定名称
  - `serial`: 子系统序列号 (SHA256 哈希的前 8 字节)

#### 5. nvmet-namespace
- **用途**: 在子系统中创建命名空间
- **参数**:
  - `nqn`: 所属子系统的 NQN
  - `namespace_id`: 命名空间 ID (对应 DRBD volume number)
  - `backing_path`: DRBD 设备路径
  - `uuid`: 命名空间 UUID
  - `nguid`: 命名空间 GUID

#### 6. nvmet-port
- **用途**: 创建 NVMe 端口 (监听地址)
- **参数**:
  - `nqns`: 要监听的子系统 NQN
  - `addr`: 监听地址 (服务 IP)
  - `type`: 传输类型 (tcp, rdma)

#### 7. Portblock (Unblock)
- **用途**: 在活跃节点上解除端口阻止

### NQN 命名规范

NVMe 限定名称 (NQN) 应遵循以下格式:

```
nqn.<year>-<month>.<domain reversed>:<unique identifier>
```

示例:
```
nqn.2024-01.com.example:storage.database
nqn.2024-01.org.linbit:sds.vm-disks
```

### UUID 生成

UUID 和 NGUID 应该是唯一标识符，可以使用以下方式生成:

```bash
# 生成 UUID
uuidgen

# 或使用 SHA256 哈希
echo -n "nqn.2024-01.com.example:subsystem.nvme-volume-1" | sha256sum | cut -c1-36 | sed 's/\(.\{8\}\)\(.\{4\}\)\(.\{4\}\)\(.\{4\}\)\(.\{12\}\)/\1-\2-\3-\4-\5/'
```

---

## 通用资源代理 (OCF)

### OCF 代理类型

drbd-reactor 配置中使用的 OCF 资源代理来自 `heartbeat` 和 `linbit` 提供集:

| 代理 | 用途 | 网关类型 |
|------|------|----------|
| `ocf:heartbeat:IPaddr2` | 虚拟 IP 地址 | 所有 |
| `ocf:heartbeat:portblock` | 端口阻止/解除 | 所有 |
| `ocf:heartbeat:Filesystem` | 文件系统挂载 | NFS, iSCSI (cluster private) |
| `ocf:heartbeat:iSCSITarget` | iSCSI Target | iSCSI |
| `ocf:heartbeat:iSCSILogicalUnit` | iSCSI LUN | iSCSI |
| `ocf:heartbeat:nfsserver` | NFS 服务器 | NFS |
| `ocf:heartbeat:exportfs` | NFS 导出 | NFS |
| `ocf:heartbeat:nvmet-subsystem` | NVMe 子系统 | NVMe-oF |
| `ocf:heartbeat:nvmet-namespace` | NVMe 命名空间 | NVMe-oF |
| `ocf:heartbeat:nvmet-port` | NVMe 端口 | NVMe-oF |

### 安装 OCF 资源代理

在 Ubuntu/Debian 上:

```bash
sudo apt-get update
sudo apt-get install resource-agents pacemaker
```

在 RHEL/CentOS 上:

```bash
sudo yum install resource-agents pacemaker
```

### 检查代理可用性

```bash
# 列出所有可用的 OCF 代理
ls /usr/lib/ocf/resource.d/heartbeat/

# 测试特定代理
crm_resource --list-agents | grep -E "IPaddr2|portblock|Filesystem|iSCSI"
```

---

## 配置管理

### 配置目录

```
/etc/drbd-reactor.d/
├── sds-iscsi-r0.toml
├── sds-nfs-data.toml
├── sds-nvmeof-database.toml
└── README
```

### 重新加载配置

修改配置后，需要重新加载 drbd-reactor:

```bash
# 方法 1: 使用 systemd
sudo systemctl reload drbd-reactor

# 方法 2: 使用信号
sudo killall -HUP drbd-reactor

# 方法 3: 自动重载 (推荐)
sudo systemctl enable drbd-reactor-reload.path
sudo systemctl start drbd-reactor-reload.path
```

### 自动重载配置

创建 `/etc/systemd/system/drbd-reactor-reload.path`:

```ini
[Unit]
Description=Watch for drbd-reactor config changes
Documentation=https://github.com/LINBIT/drbd-reactor

[Path]
PathModified=/etc/drbd-reactor.d
DirectoryNotEmpty=/etc/drbd-reactor.d

[Install]
WantedBy=multi-user.target
```

创建 `/etc/systemd/system/drbd-reactor-reload.service`:

```ini
[Unit]
Description=Reload drbd-reactor
Documentation=https://github.com/LINBIT/drbd-reactor
After=network-online.target drbd-reactor.service
Wants=network-online.target

[Service]
Type=oneshot
ExecStart=/usr/bin/systemctl reload drbd-reactor

[Install]
WantedBy=multi-user.target
```

启用:

```bash
sudo systemctl daemon-reload
sudo systemctl enable --now drbd-reactor-reload.path
```

---

## 故障排查

### 检查配置语法

```bash
# 使用 drbd-reactor 内置检查
sudo drbd-reactor --check-config

# 或使用 toml 解析器
tomlq /etc/drbd-reactor.d/sds-iscsi-r0.toml
```

### 查看日志

```bash
# 查看完整日志
sudo journalctl -u drbd-reactor -f

# 查看特定资源
sudo journalctl -u drbd-reactor -f | grep r0

# 查看错误
sudo journalctl -u drbd-reactor -p err
```

### 检查资源状态

```bash
# 使用 pcs (Pacemaker)
sudo pcs status

# 使用 crm
sudo crm_mon -1

# 检查特定资源
sudo crm_resource --resource r0 --locate
```

### 常见问题

#### 1. Portblock 失败

```
ERROR: ocf:heartbeat:portblock - unable to block port
```

**解决**: 检查是否已有进程占用该端口:

```bash
sudo ss -tlnp | grep 3260
sudo systemctl stop tgt
sudo systemctl stop iscsid
```

#### 2. IPaddr2 失败

```
ERROR: ocf:heartbeat:IPaddr2 - IP address already in use
```

**解决**: 检查 IP 是否已被使用:

```bash
sudo ip addr show | grep 192.168.1.100
# 或
arping -c 1 192.168.1.100
```

#### 3. Filesystem 挂载失败

```
ERROR: ocf:heartbeat:Filesystem - device /dev/drbd1 not found
```

**解决**: 确保 DRBD 资源已启动:

```bash
sudo drbdadm status
sudo drbdadm up r0
```

#### 4. nvmet-subsystem 失败

```
ERROR: ocf:heartbeat:nvmet-subsystem - subsystem already exists
```

**解决**: 清理现有子系统:

```bash
sudo nvmetcli list
sudo nvmetcli clear
```

---

## 最佳实践

### 1. 命名规范

- **资源名称**: 使用小写字母、数字和连字符 (例如: `database-vms`, `backup-data`)
- **NQN**: 使用反向域名格式 (例如: `nqn.2024-01.com.example:storage.db`)
- **IQN**: 使用反向域名格式 (例如: `iqn.2024-01.com.example:storage.target`)
- **导出路径**: 使用有意义的层次结构 (例如: `/srv/gateway-exports/<resource>/<volume>`)

### 2. 端口分配

| 网关类型 | 默认端口 | 备注 |
|----------|----------|------|
| iSCSI | 3260 | IANA 标准端口 |
| NFS | 2049 | IANA 标准端口 |
| NVMe-oF | 4420 | IANA 标准端口 |

### 3. 性能优化

#### iSCSI
- 使用多路径配置 (多个 Service IP)
- 启用 CHAP 认证以提高安全性
- 根据需求调整 `product_id` 和 `scsi_sn`

#### NFS
- 使用适当的导出选项 (例如: `sync`, `async`, `no_root_squash`)
- 为不同网络配置不同的 `clientspec`
- 考虑使用 NFSv4 以获得更好的性能

#### NVMe-oF
- 使用 RDMA (如果硬件支持)
- 为高 I/O 工作负载增加队列深度
- 考虑使用多个子系统以隔离工作负载

### 4. 安全性

#### iSCSI
```toml
# 启用 CHAP 认证
"ocf:heartbeat:iSCSITarget target iqn=... incoming_username=user incoming_password=pass"
```

#### NFS
```toml
# 限制客户端访问
"ocf:heartbeat:exportfs ... clientspec=192.168.1.0/24 options=rw,no_root_squash"

# 使用只读导出
"ocf:heartbeat:exportfs ... options=ro"
```

#### NVMe-oF
```toml
# 在 nvmet-subsystem 中配置主机允许列表 (需要额外配置)
# 通常通过 /etc/nvmet/configs 或 nvmet-cli 完成
```

### 5. 监控

```bash
# 监控 DRBD 状态
watch -n 1 'sudo drbdadm status'

# 监控 drbd-reactor 状态
watch -n 1 'sudo systemctl status drbd-reactor'

# 监控资源代理
sudo crm_mon -1
```

---

## 与 SDS 集成

### SDS Controller 自动生成配置

SDS Controller 应该在创建网关时自动生成 drbd-reactor 配置:

```go
// 伪代码示例
func (c *Controller) CreateISCSIGateway(req *CreateISCSIGatewayRequest) error {
    // 1. 创建 DRBD 资源
    // 2. 生成 drbd-reactor 配置
    cfg := generateISCSIPromoterConfig(req)
    // 3. 写入配置文件
    path := fmt.Sprintf("/etc/drbd-reactor.d/sds-iscsi-%s.toml", req.ResourceName)
    err := writeConfig(path, cfg)
    if err != nil {
        return err
    }
    // 4. 重新加载 drbd-reactor
    return reloadDrbdReactor()
}
```

### 配置模板

在 SDS 项目中创建配置模板:

```go
// pkg/controller/templates/iscsi_promoter.go
const ISCSIPromoterTemplate = `
# Generated by SDS Controller
# DO NOT EDIT MANUALLY

[promoter]
  [[promoter.resources.{{ .ResourceName }}]]
    runner = "systemd"
    stop-services-on-exit = true
    on-drbd-demote-failure = "reboot-immediate"
    target-as = "Requires"

    start = [
      {{- range .Agents }}
      "{{ . }}",
      {{- end }}
    ]

  [promoter.metadata]
    linstor-gateway-schema-version = 1
`
```

---

## 参考资料

- [LINSTOR Gateway 文档](https://linbit.com/drbd-user-guide/linstor-gateway-docs/)
- [DRBD Reactor 文档](https://github.com/LINBIT/drbd-reactor)
- [OCF 资源代理规范](https://github.com/ClusterLabs/resource-agents)
- [iSCSI RFC](https://tools.ietf.org/html/rfc7143)
- [NFS RFC](https://tools.ietf.org/html/rfc5661)
- [NVMe-oF 规范](https://nvmexpress.org/)

---

**版本**: 1.0
**更新时间**: 2024-01-04
**维护者**: SDS Project Team
